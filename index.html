<!DOCTYPE html>
<html>
  <head style="text-align: center;">
    <title>SC-CNN-demo: "An Effective Style Conditioning Method
      for Zero-Shot Text-to-Speech Systems"</title>
    <style>
      div {
        margin-bottom: 64px;
      }
      .first-col {
        padding-right: 40px;
        white-space: nowrap;
      }
      .text {
        font-style: italic;
        color: #666666;
      }
      audio {
        display: inline-block; 
        padding:8px; 
        width: 280px; 
        height: 40px;
      }
    </style>
  </head>
  <body style="text-align: center;">
    <article>
      <header>
        <h1>SC-CNN-demo: "An Effective Style Conditioning Method
          for Zero-Shot Text-to-Speech Systems"</h1>
      </header>
    </article>
      <a style="margin: 0 auto;"><b>Authors</b>: Hyungchan Yoon, Chanhwan Kim, Eunwoo Song, Hyun-Wook Yoon, Hong-Goo Kang</a>
    <div>
    <!-- <a href="https://github.com/hcy71o/SC-CNN"><h3>Code</h3></a> -->

    <hr>
    <div>
      <a name="ss"><h2>Abstract</h2></a>
      </td>
      <div class="container" style="max-width:700px; text-align: center; margin:0 auto; margin-top: 20px; margin-bottom: 40px">
        <p style="line-height:1.2;">
          For personalized speech generation, a neural text-to-speech (TTS) model must be successfully implemented with only a limited amount of training data from a target speaker. To this end, the baseline TTS model needs to be amply generalized to out-of-domain data (i.e., target/unseen speaker’s speech). However, approaches to address this out-of-domain generalization problem in TTS have yet to be thoroughly studied. In this work, we propose an effective pruning method for a transformer known as sparse attention, to improve the TTS model’s generalization abilities. In particular, we prune off redundant connections from self-attention layers whose attention weights are below the threshold. To flexibly determine the pruning strength for optimal generalization, we also propose a new differentiable pruning method that allows the model to automatically learn threshold values during training. Evaluations on zero-shot speaker-adaptive TTS verify the effectiveness of our method in terms of voice quality and speaker similarity.
        </p>
      </div>
      <hr>
      <a name="ss"><h2>VCTK zero-shot inference</h2></a>
      <table>
        <tbody>
          <tr>
            <td>
              <tr>
                <td class="first-col"><h4>Reference Speech</h4></td>
                <td><audio controls="" preload="none"><source src="wavs/NP/16/REF/p269_112_REF.wav"></audio></td>
                <td><audio controls="" preload="none"><source src="wavs/NP/16/REF/p298_158_REF.wav"></audio></td>
                <td><audio controls="" preload="none"><source src="wavs/NP/16/REF/p311_210_REF.wav"></audio></td>
                <td><audio controls="" preload="none"><source src="wavs/NP/16/REF/p314_179_REF.wav"></audio></td>
              </tr>
          </tr>
          <tr>
            <td class="first-col">
              <h4>Synthesized text</h4>
            </td>
            <td class="text"> 
              To the Hebrews it was a token that there would be no more universal floods. 
            </td>
            <td class="text">
              There were no passengers on board.
            </td>
            <td class="text">
              They also intend to travel today.
            </td>
            <td class="text">
              It opens the door to the Champions League.
            </td>
          </tr>
        <tr>
          <td class="first-col">ZS-FastSpeech 2</td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M1/p269_112_To_the_Heb.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M1/p298_158_There_were.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M1/p311_210_They_also_.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M1/p314_179_It_opens_t.wav"></audio></td>
        </tr>
        <!-- <tr>
          <td class="first-col">ZS-AdaSpeech</td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M2/p269_112_To_the_Heb.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M2/p298_158_There_were.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M2/p311_210_They_also_.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M2/p314_179_It_opens_t.wav"></audio></td>
        </tr> -->
        <tr>
          <td class="first-col">StyleSpeech</td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M3/p269_112_To_the_Heb.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M3/p298_158_There_were.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M3/p311_210_They_also_.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M3/p314_179_It_opens_t.wav"></audio></td>
        </tr>
        <tr>
          <td class="first-col">SC-CNN</td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M4/p269_112_To_the_Heb.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M4/p298_158_There_were.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M4/p311_210_They_also_.wav"></audio></td>
          <td><audio controls="" preload="none"><source src="wavs/NP/16/M4/p314_179_It_opens_t.wav"></audio></td>
        </tr>
        </tbody>
      </table>

    </div>
  </body>
</html>
